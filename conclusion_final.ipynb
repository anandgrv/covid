{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 7. Predicting confirmed cases using all variables\n",
    "\n",
    "In this linear model we used all the variables as predictor. To avoid model overfitting the data that is used to build the model we decided to use a 10-fold cross-validation splitting the data in train_set and test_set.\n",
    "\n",
    "Using the cross-validation method, we ended up with a RMSE (root mean-squared error) of 22841.2 while the MAE value of 16529.69. These numbers are comparable, so the difference between these values doesn’t look alarming.\n",
    "\n",
    "In terms of residuals vs. fitted values, we see an improvement in the performance of this model which is translated by an increase in the adjusted R2, we confirm that this model is also optimal one given our analyses resulting in R2 value of 95%.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions & Further Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "After cleaning and preprocessing the data, looking carefully into the relationship between all predictors as well as their relationships with the outcome variables, we went ahead with the analysis of the data. First, we wanted to use this data to predict the number of confirmed cases based on chosen predictors.\n",
    "After going through a deep analysis of different models & comparing them with respect to different metrics, we concluded that the best performing model was the following: \n",
    "● Outcome variable: Global_conf \n",
    "● Predictors: Recovery and Death as 2nd degree polynomial\n",
    "This model yielded us with an adjusted R-squared value of 95% which we found to be an indicator of an accurate prediction for future values.\n",
    "\n",
    "## Further Steps:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Regression assumptions : \n",
    "Linear regression makes several assumptions about the data, such as :\n",
    "\n",
    "**1.1 Linearity of the data:** The relationship between the predictor (x) and the outcome (y) is assumed to be linear.\n",
    "\n",
    "**1.2 Normality of residuals:** The residual errors are assumed to be normally distributed.\n",
    "\n",
    "**1.3 Homogeneity of residuals variance:** The residuals are assumed to have a constant variance (homoscedasticity)\n",
    "\n",
    "**1.4 Independence of residuals error terms.**\n",
    "\n",
    "###  2. Residual Distribution: \n",
    "The evidence that a linear regression model is appropriate comes in from the residual vs fitted plot, whose values are randomly dispersed around the horizontal axis, showing that the mean of residuals is really close to 0. Moreover, the Normal Q-Q plot ensures that the distribution of residuals is Gaussian one.\n",
    "\n",
    "### 3. Regression diagnostics : \n",
    "The diagnostic plots show residuals in four different ways:\n",
    "\n",
    "**3.1 Residuals vs Fitted.** Used to check the linear relationship assumptions. A horizontal line, without distinct patterns is an indication for a linear relationship, what is good.\n",
    "\n",
    "**3.2 Normal Q-Q:** Used to examine whether the residuals are normally distributed. It’s good if residuals points follow the straight dashed line. “homogeneity of variance”\n",
    "\n",
    "**3.3 Scale-Location (or Spread-Location):** Used to check the homogeneity of variance of the residuals (homoscedasticity). Horizontal line with equally spread points is a good indication of homoscedasticity. This is not the case in our example, where we have a heteroscedasticity problem.\n",
    "\n",
    "**3.4 Residuals vs Leverage:** Used to identify influential cases, that is extreme values that might influence the regression results when included or excluded from the analysis. This plot will be described further in the next sections.\n",
    "\n",
    "\n",
    "### 4. Regression Model Evaluation Metrics: \n",
    "The MSE, MAE, RMSE, and R-Squared metrics are mainly used to evaluate the prediction error rates and model performance in regression analysis.\n",
    "\n",
    "\n",
    "**4.1 MAE (Mean absolute error):** It represents the difference between the original and predicted values extracted by averaged the absolute difference over the data set.\n",
    "$${\\displaystyle \\operatorname {MAE} ={\\frac {1}{n}}\\sum _{i=1}^{n}(Y_{i}-{\\hat {Y_{i}}}).}$$\n",
    "\n",
    "\n",
    "**4.2 MSE (Mean Squared Error):** It represents the difference between the original and predicted values extracted by squared the average difference over the data set.\n",
    "$${\\displaystyle \\operatorname {MSE} ={\\frac {1}{n}}\\sum _{i=1}^{n}(Y_{i}-{\\hat {Y_{i}}})^{2}.}$$\n",
    "\n",
    "\n",
    "**4.3 RMSE (Root Mean Squared Error):** It is the error rate by the square root of MSE.\n",
    "\n",
    "\n",
    "$${\\displaystyle \\operatorname {RMSE} ={\\sqrt{MSE}} = {\\sqrt {\\frac {1}{n}\\sum _{i=1}^{n}(Y_{i}-{\\hat {Y_{i}}})^{2}}}.}$$\n",
    "\n",
    "\n",
    "where $Y_{i}$ is the original value and ${\\hat {Y_{i}}}$ is the predicted one.\n",
    "\n",
    "\n",
    "**4.4 R-squared (Coefficient of determination):** It represents the coefficient of how well the values fit compared to the original values. The value from 0 to 1 interpreted as percentages. The higher the value is, the better the model is.\n",
    "\n",
    "**4.5 Adjusted R-squared:** It is a model version of R-squared that has been adjusted for the number of predictors in the model. It increases only when an independent variable is significant and affects the dependent variable.\n",
    "\n",
    "Formula: where is the sample adj.R2 = 1 − (1 − R2)[n − 1/n − (k + 1)] n size and k is the number of independent variables in the regression equation.\n",
    "\n",
    "**4.6 p_value:** A predictor that has a low p_value (<0.05) indicates that we should reject the null hypothesis. In other words, a predictor that has a low p_value is likely to be a meaningful addition to our model because changes in the predictor’s value are related to changes in the response variable. Conversely, a larger (insignificant) p_value suggests that changes in the predictor are not associated with changes in response.\n",
    "\n",
    "\n",
    "### 5. Cross Validation:\n",
    "\n",
    "The basic idea behind cross validation techniques, consists of dividing the data into two sets:\n",
    "\n",
    "a. The training set: used to build the model;\n",
    "\n",
    "b. The validation (test) set used to validate (test) the model by estimating the prediction error.\n",
    "\n",
    "In our case, we used K-fold cross validation, assigning the value of k= 10, so we split the data into 10 subsets. The k-fold CV is a robust method for estimating the accuracy of a model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
